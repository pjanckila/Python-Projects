{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a python code to extract data from many tables in bigquery using a loop"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing all necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-bigquery in c:\\users\\skicr\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.11.3)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.47.0 in c:\\users\\skicr\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-cloud-bigquery) (1.56.0)\n",
      "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in c:\\users\\skicr\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-cloud-bigquery) (2.11.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.15.0 in c:\\users\\skicr\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-cloud-bigquery) (1.22.3)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in c:\\users\\skicr\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-cloud-bigquery) (2.3.3)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in c:\\users\\skicr\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-cloud-bigquery) (2.5.0)\n",
      "Requirement already satisfied: packaging>=20.0.0 in c:\\users\\skicr\\appdata\\roaming\\python\\python311\\site-packages (from google-cloud-bigquery) (23.1)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in c:\\users\\skicr\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-cloud-bigquery) (4.23.4)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in c:\\users\\skicr\\appdata\\roaming\\python\\python311\\site-packages (from google-cloud-bigquery) (2.8.2)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.21.0 in c:\\users\\skicr\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-cloud-bigquery) (2.31.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\skicr\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (1.59.1)\n",
      "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in c:\\users\\skicr\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (2.22.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\skicr\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (1.56.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in c:\\users\\skicr\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery) (1.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\skicr\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\skicr\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\skicr\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\skicr\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\skicr\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (2023.5.7)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\skicr\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\skicr\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\skicr\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\skicr\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (0.5.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\skicr\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.25.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#%pip install dbapi \n",
    "%pip install --upgrade google-cloud-bigquery\n",
    "#%pip install db-dtypes\n",
    "\n",
    "\n",
    "\n",
    "#import db_dtypes \n",
    "#import dbapi\n",
    "#import datetime\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a google cloud bigquery client using a service account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery # to run queries on google clouds bigquery\n",
    "from google.oauth2 import service_account # to acess google cloud using a service account\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    r\"C:\\Users\\skicr\\Downloads\\alpine-tempo-392622-523114992507.json\"\n",
    ") \n",
    "google_cloud_project_id = 'alpine-tempo-392622' \n",
    "client = bigquery.Client(credentials=credentials,project=google_cloud_project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = range(1950,2023)\n",
    "queries = []\n",
    "for year in years: \n",
    "    query=('''\n",
    "            SELECT\n",
    "                states.state,\n",
    "                storm_data.deaths,\n",
    "                storm_data.injuries,\n",
    "                storm_data.damage\n",
    "            FROM\n",
    "              (\n",
    "                SELECT\n",
    "                  SUM(deaths_direct+deaths_indirect) AS deaths, \n",
    "                  SUM(injuries_direct+injuries_indirect)  AS injuries, \n",
    "                  SUM(damage_crops+damage_property) AS damage,\n",
    "                  LPAD(state_fips_code,2,'0') as fips_code\n",
    "                FROM\n",
    "                  `bigquery-public-data.noaa_historic_severe_storms.storms_{year}`\n",
    "                GROUP BY\n",
    "                fips_code\n",
    "              ) as storm_data\n",
    "            RIGHT JOIN \n",
    "              `bigquery-public-data.geo_us_boundaries.states` AS states \n",
    "            ON \n",
    "              states.state_fips_code=storm_data.fips_code                               \n",
    "            ORDER by \n",
    "              states.state\n",
    "            ''').format(year=year)\n",
    "    \n",
    "    queries.append(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results_list=[]\n",
    "\n",
    "for x, query in enumerate(queries):\n",
    "   query = client.query(queries[x])\n",
    "   query_res = query.result().to_dataframe()\n",
    "   query_res.insert(4,'year',years[x])\n",
    "   results_list.append(query_res)\n",
    "results_df=pd.concat(results_list,ignore_index=True)\n",
    "results_df=results_df.convert_dtypes()\n",
    "results_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install cpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cpi\n",
    "\n",
    "inflation_factor = {}\n",
    "for year in years:\n",
    "   inflation_factor[year] = cpi.inflate(1,year)\n",
    "inflation_factor\n",
    "\n",
    "results_df['infl_adj_damage'] = results_df.apply(lambda row: row['damage']*inflation_factor[row['year']],axis=1)\n",
    "\n",
    "results_df.dtypes\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping the US Censes Bureau Website to create columns for deaths and injuries normalized by population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%pip install us "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env DC_STATEHOOD = 1\n",
    "import us\n",
    "def state_code_lookup(state_name):\n",
    "    \n",
    "    if type(state_name)==str:\n",
    "        state_name=state_name.lstrip('.')\n",
    "        if us.states.lookup(state_name) is not None:\n",
    "            return us.states.lookup(state_name).abbr\n",
    "    else:\n",
    "        return \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "census_url = 'https://www.census.gov/data/tables/time-series/dec/popchange-data-text.html'\n",
    "census_html = requests.get(census_url).text\n",
    "popdf=pd.read_html(census_html)\n",
    "popdf=popdf[0]\n",
    "popdf.set_index('State or Region',inplace=True)\n",
    "popdf.head()\n",
    "consol_df = pd.DataFrame(columns=['state','population','year'])\n",
    "cols = [*(popdf.columns)]\n",
    "i=1\n",
    "for col in cols:\n",
    "    a=[*popdf[col]]\n",
    "    for x,y in  enumerate(a):\n",
    "        if a[x] == str(us.states.lookup(a[x])):\n",
    "            if int(col[:4]) < 1950:\n",
    "                break\n",
    "            else:\n",
    "                newrow=pd.DataFrame({'state':state_code_lookup(a[x]),'population':int(a[x+1]),'year':int(col[:4])},index=[0])\n",
    "                consol_df=pd.concat([consol_df,newrow],ignore_index=True)\n",
    "\n",
    "\n",
    "consol_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "consol_df = consol_df.astype({'population':np.int64})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging the two sets of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merged_df = results_df.merge(consol_df,on=['state','year'],how='left')\n",
    "merged_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merged_df.set_index(['state'],inplace=True)\n",
    "states =[*merged_df.index.drop_duplicates()]\n",
    "\n",
    "merged_df.sort_values(['state','year'],inplace=True)\n",
    "for state in states:\n",
    "    merged_df.loc[state,'population'].interpolate(method='linear',inplace=True)\n",
    "merged_df.head(),merged_df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.fillna(0,inplace=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install beautifulsoup4\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = 'https://www.census.gov/data/tables/time-series/demo/popest/2020s-state-total.html#v2022'\n",
    "html=requests.get(url).text\n",
    "soup = bs(html,'html.parser')\n",
    "filetracks = soup.find_all('a',filetrack=True,href=True)\n",
    "filetrack=filetracks[2].get('href')\n",
    "print(filetrack)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "from urllib.parse import urlunparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filetrack=urlunparse(urlparse(filetrack,scheme='https'))\n",
    "filetrack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openpyxl\n",
    "import openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_pop_data = pd.read_excel(filetrack)\n",
    "more_pop_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_pop_data=more_pop_data.iloc[:,[0,3,4]]\n",
    "trimmed_pop_data['State']=trimmed_pop_data.iloc[:,0].apply(state_code_lookup)\n",
    "trimmed_pop_data.drop('table with row headers in column A and column headers in rows 3 through 5. (leading dots indicate sub-parts)',axis=1, inplace=True)\n",
    "trimmed_pop_data.set_index('State', inplace=True)\n",
    "trimmed_pop_data.rename(columns={'Unnamed: 3':'2021','Unnamed: 4':'2022'},inplace=True)\n",
    "trimmed_pop_data.head(10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_update=[]\n",
    "for state in states:\n",
    "    if state in [*(trimmed_pop_data.index)]:\n",
    "        for year in [*(trimmed_pop_data.columns)]:\n",
    "            row_update.append({'state':state,'year':year,'population':trimmed_pop_data.loc[state,year]})\n",
    "yet_another_df=pd.DataFrame(row_update)\n",
    "yet_another_df.set_index('state',inplace=True)\n",
    "yet_another_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in row_update:\n",
    "    merged_df.loc[(x['state'],int(x['year'])),'population']=x['population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_df=merged_df.reset_index()\n",
    "final_df = final_df.astype({'population':np.int64,'infl_adj_damage':np.int64})\n",
    "final_df['deaths/100k']=final_df.apply(lambda x: x['deaths']/x['population']*100000, axis=1)  \n",
    "final_df['injuries/100k']=final_df.apply(lambda x: x['injuries']/x['population']*100000, axis=1)\n",
    "final_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some rows still don't have population data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_to_drop=[*final_df.loc[final_df['population']==0].index]\n",
    "final_df.drop(index=rows_to_drop,axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['deaths/100k']=final_df.apply(lambda x: x['deaths']/x['population']*100000, axis=1)  \n",
    "final_df['injuries/100k']=final_df.apply(lambda x: x['injuries']/x['population']*100000, axis=1)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install XlsxWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlsxwriter\n",
    "#with pd.ExcelWriter(r'c:\\Users\\skicr\\Documents\\Python Scripts\\NOAA Storm Data\\storm data by year.xlsx') as writer:\n",
    "final_df.to_excel(pd.ExcelWriter(r'c:\\Users\\skicr\\Documents\\Python Scripts\\NOAA Storm Data\\storm data by year.xlsx'),index=False,)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
